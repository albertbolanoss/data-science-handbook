{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier\n",
    "\n",
    "References:\n",
    "[Gradient Boosting Classifier](https://towardsdatascience.com/all-you-need-to-know-about-gradient-boosting-algorithm-part-1-regression-2520a34a502)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom GBM RMSE: 16.46861\n",
      "Scikit-learn GBM RMSE: 16.46861\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class CustomGradientBoostingRegressor:\n",
    "    \n",
    "    def __init__(self, learning_rate=0.1, n_estimators=20, max_depth=1):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.trees = []\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.F0 = y.mean()\n",
    "        Fm = np.full(y.shape, self.F0)\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            residuals = y - Fm\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth, random_state=0)\n",
    "            tree.fit(X, residuals)\n",
    "            gamma = tree.predict(X)\n",
    "            Fm += self.learning_rate * gamma\n",
    "            self.trees.append(tree)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        Fm = np.full(X.shape[0], self.F0)\n",
    "        for tree in self.trees:\n",
    "            Fm += self.learning_rate * tree.predict(X)\n",
    "        return Fm\n",
    "\n",
    "# Generar datos sint√©ticos\n",
    "X, y = make_regression(n_samples=100, n_features=1, noise=10, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modelo personalizado\n",
    "custom_gbm = CustomGradientBoostingRegressor(n_estimators=20, learning_rate=0.1, max_depth=1)\n",
    "custom_gbm.fit(X_train, y_train)\n",
    "y_pred_custom = custom_gbm.predict(X_test)\n",
    "custom_gbm_rmse = np.sqrt(mean_squared_error(y_test, y_pred_custom))\n",
    "\n",
    "print(f\"Custom GBM RMSE: {custom_gbm_rmse:.5f}\")\n",
    "\n",
    "# Modelo de scikit-learn instance of the custom model (This way is how use this model directly from scikit-learn)\n",
    "sklearn_gbm = GradientBoostingRegressor(n_estimators=20, learning_rate=0.1, max_depth=1)\n",
    "sklearn_gbm.fit(X_train, y_train)\n",
    "y_pred_sklearn = sklearn_gbm.predict(X_test)\n",
    "sklearn_gbm_rmse = np.sqrt(mean_squared_error(y_test, y_pred_sklearn))\n",
    "\n",
    "print(f\"Scikit-learn GBM RMSE: {sklearn_gbm_rmse:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Squared Error (MSE)\n",
    "Es una m√©trica de evaluaci√≥n que mide qu√© tan lejos est√°n las predicciones del modelo con respecto a los valores reales. Se calcula como:\n",
    "\n",
    "üîπ Interpretaci√≥n:\n",
    "\n",
    "Valores m√°s bajos indican un mejor modelo.\n",
    "\n",
    "Penaliza m√°s los errores grandes debido a la elevaci√≥n al cuadrado.\n",
    "\n",
    "## Root Mean Squared Error (RMSE)\n",
    "La ra√≠z cuadrada del MSE:\n",
    "\n",
    "üîπ ¬øPor qu√© usamos RMSE en lugar de MSE?\n",
    "\n",
    "El MSE est√° en unidades cuadradas y no es f√°cil de interpretar.\n",
    "\n",
    "El RMSE devuelve el error en las mismas unidades que los datos originales.\n",
    "\n",
    "\n",
    "¬øPor qu√© comparamos RMSE entre el modelo personalizado y Scikit-learn?\n",
    "Nos ayuda a ver qu√© tan cerca est√° nuestra implementaci√≥n manual del algoritmo de Gradient Boosting en Scikit-learn.\n",
    "\n",
    "Si los valores de RMSE son similares para ambos modelos, significa que nuestra implementaci√≥n funciona correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Cargar el dataset de iris\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y prueba (80% entrenamiento, 20% prueba)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear y entrenar el modelo Gradient Boosting\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones en el conjunto de prueba\n",
    "y_pred = gb_clf.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Precisi√≥n del modelo: {accuracy:.2f}\")\n",
    "print(\"\\nReporte de clasificaci√≥n:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Matriz de confusi√≥n\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nMatriz de confusi√≥n:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Visualizaci√≥n de la importancia de las caracter√≠sticas\n",
    "feature_importance = gb_clf.feature_importances_\n",
    "plt.barh(iris.feature_names, feature_importance)\n",
    "plt.xlabel(\"Importancia de la caracter√≠stica\")\n",
    "plt.ylabel(\"Caracter√≠sticas\")\n",
    "plt.title(\"Importancia de las caracter√≠sticas en Gradient Boosting\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
