{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost Classified\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Generar datos de ejemplo\n",
    "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
    "\n",
    "# Dividir en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definir el clasificador base (√°rbol de decisi√≥n con profundidad 1)\n",
    "base_clf = DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "# Crear y entrenar el modelo AdaBoost\n",
    "ada_clf = AdaBoostClassifier(base_estimator=base_clf, n_estimators=50, learning_rate=1.0, random_state=42)\n",
    "ada_clf.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones\n",
    "y_pred = ada_clf.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Precisi√≥n de AdaBoost: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost (Adaptive Boosting) es un algoritmo de aprendizaje autom√°tico supervisado que se utiliza principalmente para problemas de clasificaci√≥n. Se basa en la idea de boosting, que combina m√∫ltiples clasificadores d√©biles para formar un clasificador fuerte.\n",
    "\n",
    "## Conceptos Clave\n",
    "Clasificadores d√©biles\n",
    "\n",
    "AdaBoost utiliza clasificadores simples llamados \"d√©bilmente aprendices\" (weak learners), como los √°rboles de decisi√≥n con una sola divisi√≥n (stumps).\n",
    "\n",
    "Estos clasificadores tienen una precisi√≥n ligeramente mejor que el azar (~50%-60%).\n",
    "\n",
    "Iteraciones y pesos\n",
    "\n",
    "AdaBoost entrena secuencialmente m√∫ltiples clasificadores, ajustando los pesos de las instancias mal clasificadas en cada iteraci√≥n.\n",
    "\n",
    "Los ejemplos dif√≠ciles reciben mayor peso, lo que obliga al modelo a enfocarse en ellos en la siguiente iteraci√≥n.\n",
    "\n",
    "Combinaci√≥n de clasificadores\n",
    "\n",
    "Cada clasificador tiene un peso de importancia en funci√≥n de su precisi√≥n.\n",
    "\n",
    "La predicci√≥n final se obtiene mediante una votaci√≥n ponderada de todos los clasificadores d√©biles.\n",
    "\n",
    "\n",
    "## C√≥mo Funciona AdaBoost\n",
    "Inicializaci√≥n\n",
    "\n",
    "Se asigna un peso igual a todas las instancias del conjunto de entrenamiento.\n",
    "\n",
    "Entrenamiento Iterativo\n",
    "\n",
    "Se entrena un clasificador d√©bil (por ejemplo, un √°rbol de decisi√≥n simple).\n",
    "\n",
    "Se eval√∫a su desempe√±o y se ajustan los pesos:\n",
    "\n",
    "Ejemplos mal clasificados ‚Üí Se les asigna m√°s peso.\n",
    "\n",
    "Ejemplos bien clasificados ‚Üí Se les reduce el peso.\n",
    "\n",
    "Se repite el proceso con un nuevo clasificador d√©bil.\n",
    "\n",
    "Predicci√≥n Final\n",
    "\n",
    "Se combinan todos los clasificadores entrenados mediante una votaci√≥n ponderada para obtener la clasificaci√≥n final.\n",
    "\n",
    "\n",
    "Ventajas de AdaBoost\n",
    "‚úÖ Mejora el rendimiento al combinar m√∫ltiples clasificadores d√©biles.\n",
    "‚úÖ Se enfoca en los errores, lo que lo hace m√°s preciso en problemas complejos.\n",
    "‚úÖ Robusto ante sobreajuste en la mayor√≠a de los casos, si se usa correctamente.\n",
    "‚úÖ Compatible con muchos clasificadores base (no solo √°rboles de decisi√≥n).\n",
    "\n",
    "üîπ Desventajas de AdaBoost\n",
    "‚ùå Sensible al ruido en los datos (puede dar demasiado peso a outliers).\n",
    "‚ùå Menos eficiente en grandes conjuntos de datos, ya que el entrenamiento es secuencial.\n",
    "‚ùå Depende de clasificadores d√©biles adecuados, si son demasiado d√©biles o demasiado fuertes, puede afectar el rendimiento.\n",
    "\n",
    "üîπ Casos de Uso\n",
    "\n",
    "- Detecci√≥n de rostros y objetos.\n",
    "- Filtrado de spam en correos electr√≥nicos.\n",
    "- Diagn√≥stico m√©dico basado en datos cl√≠nicos.\n",
    "- An√°lisis de fraudes en transacciones financieras."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
