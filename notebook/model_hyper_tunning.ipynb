{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimización de Hiperparámetros con GridSearchCV para KNN\n",
    "\n",
    "Explicación del Código Existente\n",
    "El código proporcionado implementa una búsqueda de hiperparámetros para un clasificador KNN (K-Nearest Neighbors) usando GridSearchCV. Vamos a analizarlo y completarlo:\n",
    "\n",
    "\n",
    "https://towardsdatascience.com/gridsearchcv-for-beginners-db48a90114ee/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 384 candidates, totalling 1920 fits\n",
      "\n",
      "Mejores parámetros encontrados:\n",
      "{'knn__algorithm': 'auto', 'knn__leaf_size': 10, 'knn__n_neighbors': 7, 'knn__p': 1, 'knn__weights': 'uniform'}\n",
      "\n",
      "Mejor score de validación cruzada:\n",
      "0.9524\n",
      "\n",
      "Training accuracy: 0.9333\n",
      "Test accuracy: 1.0000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[19  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0 13]]\n",
      "\n",
      "Top 5 combinaciones de hiperparámetros:\n",
      "    param_knn__n_neighbors param_knn__weights param_knn__algorithm  \\\n",
      "32                       7            uniform                 auto   \n",
      "34                       7            uniform                 auto   \n",
      "35                       7           distance                 auto   \n",
      "36                       9            uniform                 auto   \n",
      "8                        7            uniform                 auto   \n",
      "\n",
      "    mean_test_score  rank_test_score  \n",
      "32         0.952381                1  \n",
      "34         0.952381                1  \n",
      "35         0.952381                1  \n",
      "36         0.952381                1  \n",
      "8          0.952381                1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 1. Cargar datos (ejemplo con datos iris)\n",
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# 2. Dividir datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 3. Crear pipeline con escalado y modelo KNN\n",
    "knn_pipe = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# 4. Definir espacio de búsqueda de hiperparámetros\n",
    "param_grid = {\n",
    "    'knn__n_neighbors': range(3, 15, 2),\n",
    "    'knn__weights': ['uniform', 'distance'],\n",
    "    'knn__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'knn__leaf_size': [10, 20, 30, 40],\n",
    "    'knn__p': [1, 2]  # 1: distancia Manhattan, 2: distancia Euclidiana\n",
    "}\n",
    "\n",
    "# 5. Configurar GridSearchCV\n",
    "gs_knn = GridSearchCV(\n",
    "    estimator=knn_pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    n_jobs=-1,  # Usar todos los núcleos del CPU\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 6. Ajustar el modelo\n",
    "gs_knn.fit(X_train, y_train)\n",
    "\n",
    "# 7. Resultados\n",
    "print(\"\\nMejores parámetros encontrados:\")\n",
    "print(gs_knn.best_params_)\n",
    "\n",
    "print(\"\\nMejor score de validación cruzada:\")\n",
    "print(f\"{gs_knn.best_score_:.4f}\")\n",
    "\n",
    "# 8. Evaluar en conjunto de entrenamiento y prueba\n",
    "train_score = gs_knn.score(X_train, y_train)\n",
    "test_score = gs_knn.score(X_test, y_test)\n",
    "print(f\"\\nTraining accuracy: {train_score:.4f}\")\n",
    "print(f\"Test accuracy: {test_score:.4f}\")\n",
    "\n",
    "# 9. Reporte de clasificación detallado\n",
    "y_pred = gs_knn.predict(X_test)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 10. Matriz de confusión\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# 11. DataFrame con resultados de la búsqueda\n",
    "results_df = pd.DataFrame(gs_knn.cv_results_)\n",
    "print(\"\\nTop 5 combinaciones de hiperparámetros:\")\n",
    "print(results_df.sort_values('rank_test_score').head(5)[[\n",
    "    'param_knn__n_neighbors',\n",
    "    'param_knn__weights',\n",
    "    'param_knn__algorithm',\n",
    "    'mean_test_score',\n",
    "    'rank_test_score'\n",
    "]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicación de Conceptos Clave\n",
    "1. Hiperparámetros en KNN\n",
    "Los hiperparámetros son configuraciones del modelo que no se aprenden de los datos:\n",
    "\n",
    "n_neighbors: Número de vecinos a considerar (K)\n",
    "\n",
    "weights: Cómo ponderar los vecinos ('uniform' = igual peso, 'distance' = peso por distancia inversa)\n",
    "\n",
    "algorithm: Algoritmo para computar los vecinos más cercanos\n",
    "\n",
    "leaf_size: Tamaño de hoja para estructuras de árbol (afecta velocidad)\n",
    "\n",
    "p: Parámetro de distancia (1=Manhattan, 2=Euclidiana)\n",
    "\n",
    "2. GridSearchCV\n",
    "Técnica de búsqueda exhaustiva que:\n",
    "\n",
    "Prueba todas las combinaciones posibles de hiperparámetros\n",
    "\n",
    "Usa validación cruzada para evaluar cada combinación\n",
    "\n",
    "Selecciona la combinación con mejor rendimiento\n",
    "\n",
    "3. Pipeline\n",
    "Secuencia de transformaciones con un estimador final:\n",
    "\n",
    "MinMaxScaler: Normaliza características al rango [0,1]\n",
    "\n",
    "KNeighborsClassifier: Modelo KNN\n",
    "\n",
    "4. Ventajas de este enfoque\n",
    "Optimización sistemática: Encuentra la mejor combinación de parámetros\n",
    "\n",
    "Prevención de overfitting: Usa validación cruzada\n",
    "\n",
    "Reproducibilidad: Proceso automatizado y documentado\n",
    "\n",
    "Mejor rendimiento: Modelo ajustado específicamente para los datos\n",
    "\n",
    "5. Interpretación de Resultados\n",
    "best_params_: La mejor combinación encontrada\n",
    "\n",
    "best_score_: El mejor score de validación cruzada\n",
    "\n",
    "cv_results_: Resultados detallados de todas las combinaciones\n",
    "\n",
    "score(): Rendimiento en datos de entrenamiento/prueba\n",
    "\n",
    "Recomendaciones Prácticas\n",
    "Rangos de búsqueda:\n",
    "\n",
    "Comienza con rangos amplios y luego afina\n",
    "\n",
    "Para n_neighbors, prueba valores impares (evita empates)\n",
    "\n",
    "Métricas alternativas:\n",
    "\n",
    "Considera usar 'f1_weighted' para problemas multiclase desbalanceados\n",
    "\n",
    "Optimización de tiempo:\n",
    "\n",
    "Usa n_jobs=-1 para paralelizar la búsqueda\n",
    "\n",
    "Reduce cv si los datos son grandes\n",
    "\n",
    "Validación final:\n",
    "\n",
    "Siempre evalúa en un conjunto de test independiente\n",
    "\n",
    "Compara con el score de validación cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🔍 **Diferencia entre Parámetros e Hiperparámetros en Machine Learning**\n",
    "\n",
    "| **Característica**       | **Parámetros**                                  | **Hiperparámetros**                          |\n",
    "|--------------------------|-----------------------------------------------|---------------------------------------------|\n",
    "| **Definición**           | Variables **aprendidas** por el modelo durante el entrenamiento. | Variables **configuradas antes** del entrenamiento. |\n",
    "| **Quién los define**     | El modelo (ajuste automático con los datos).   | El científico de datos (elección manual o mediante búsqueda). |\n",
    "| **Ejemplos**            | - Pesos en una red neuronal.<br>- Coeficientes en regresión lineal. | - Número de vecinos en KNN.<br>- Tasa de aprendizaje en redes neuronales. |\n",
    "| **Objetivo**            | Minimizar la función de pérdida (ej: error).   | Optimizar el rendimiento general del modelo. |\n",
    "| **Modificación**        | Se actualizan en cada iteración (backpropagation, SGD). | Se prueban combinaciones (GridSearch, RandomSearch). |\n",
    "| **Influencia**           | Determina **cómo** el modelo hace predicciones. | Determina **qué tan bien** el modelo puede aprender. |\n",
    "\n",
    "---\n",
    "\n",
    "### 📌 **Ejemplo Práctico**  \n",
    "**Modelo: Red Neuronal**  \n",
    "- **Parámetros**: Pesos de las conexiones entre neuronas (ajustados durante el entrenamiento).  \n",
    "- **Hiperparámetros**:  \n",
    "  - Número de capas ocultas.  \n",
    "  - Función de activación (ReLU, sigmoide).  \n",
    "  - Tasa de aprendizaje (`learning_rate`).  \n",
    "\n",
    "---\n",
    "\n",
    "### 🎯 **¿Por qué importa la diferencia?**  \n",
    "1. **Parámetros**:  \n",
    "   - Si el modelo no converge, revisa el algoritmo de optimización o los datos.  \n",
    "2. **Hiperparámetros**:  \n",
    "   - Si el modelo no generaliza bien, ajusta hiperparámetros (ej: regularización). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
