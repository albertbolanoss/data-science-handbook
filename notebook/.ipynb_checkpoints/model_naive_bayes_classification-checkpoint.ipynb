{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naives Bayes Classification\n",
    "\n",
    "# References:\n",
    "- [Naives Bayes Classification](https://jakevdp.github.io/PythonDataScienceHandbook/05.05-naive-bayes.html)\n",
    "- [Video](https://youtu.be/O2L2Uv9pdDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problema: Diagnosticar una enfermedad rara\n",
    "Contexto:\n",
    "\n",
    "Una enfermedad rara afecta al 1% de la población (P(Enfermo) = 0.01)\n",
    "\n",
    "Existe una prueba médica con:\n",
    "\n",
    "99% de precisión para detectar la enfermedad (verdaderos positivos)\n",
    "\n",
    "5% de falsos positivos (personas sanas que dan positivo)\n",
    "\n",
    "Pregunta: Si un paciente da positivo, ¿cuál es la probabilidad real de que esté enfermo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidad de estar enfermo dado un resultado positivo: 16.67%\n"
     ]
    }
   ],
   "source": [
    "def teorema_bayes(p_a, p_b_dado_a, p_b_dado_no_a):\n",
    "    \"\"\"\n",
    "    Calcula P(A|B) usando el teorema de Bayes\n",
    "    \n",
    "    Parámetros:\n",
    "    p_a: P(A) - Probabilidad previa del evento A\n",
    "    p_b_dado_a: P(B|A) - Probabilidad de B dado A\n",
    "    p_b_dado_no_a: P(B|¬A) - Probabilidad de B dado no A\n",
    "    \n",
    "    Retorna:\n",
    "    P(A|B) - Probabilidad de A dado B\n",
    "    \"\"\"\n",
    "    # Calculamos P(B) usando la ley de probabilidad total\n",
    "    p_b = p_b_dado_a * p_a + p_b_dado_no_a * (1 - p_a)\n",
    "    \n",
    "    # Aplicamos el teorema de Bayes\n",
    "    p_a_dado_b = (p_b_dado_a * p_a) / p_b\n",
    "    \n",
    "    return p_a_dado_b\n",
    "\n",
    "# Probabilidades del problema\n",
    "p_enfermo = 0.01          # Prevalencia de la enfermedad\n",
    "p_positivo_enfermo = 0.99  # Sensibilidad de la prueba\n",
    "p_positivo_sano = 0.05     # Tasa de falsos positivos\n",
    "\n",
    "# Calculamos la probabilidad de estar enfermo dado un positivo\n",
    "probabilidad = teorema_bayes(p_enfermo, p_positivo_enfermo, p_positivo_sano)\n",
    "\n",
    "print(f\"Probabilidad de estar enfermo dado un resultado positivo: {probabilidad:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidad predicha por el modelo:\n",
      "P(Enfermo|Positivo) = 99.55%\n",
      "P(Enfermo|Negativo) = 0.00%\n",
      "\n",
      "Proporción real en los datos simulados:\n",
      "P(Enfermo|Positivo) real = 16.08%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Simulamos datos para 100,000 pacientes\n",
    "np.random.seed(42)\n",
    "n_pacientes = 100000\n",
    "\n",
    "# 1% enfermos (clase 1), 99% sanos (clase 0)\n",
    "enfermos = np.random.choice([0, 1], size=n_pacientes, p=[0.99, 0.01])\n",
    "\n",
    "# Simulamos resultados de pruebas\n",
    "pruebas = np.zeros(n_pacientes)\n",
    "\n",
    "# Para enfermos: 99% positivos (1), 1% negativos (0)\n",
    "enfermo_idx = np.where(enfermos == 1)[0]\n",
    "pruebas[enfermo_idx] = np.random.choice([0, 1], size=len(enfermo_idx), p=[0.01, 0.99])\n",
    "\n",
    "# Para sanos: 5% positivos (1), 95% negativos (0)\n",
    "sano_idx = np.where(enfermos == 0)[0]\n",
    "pruebas[sano_idx] = np.random.choice([0, 1], size=len(sano_idx), p=[0.95, 0.05])\n",
    "\n",
    "# Preparamos los datos para scikit-learn\n",
    "X = pruebas.reshape(-1, 1)  # Resultado de la prueba\n",
    "y = enfermos                # Estado real\n",
    "\n",
    "# Entrenamos el modelo Naive Bayes\n",
    "model = GaussianNB()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Hacemos predicciones para positivo (1) y negativo (0)\n",
    "print(\"Probabilidad predicha por el modelo:\")\n",
    "print(f\"P(Enfermo|Positivo) = {model.predict_proba([[1]])[0][1]:.2%}\")\n",
    "print(f\"P(Enfermo|Negativo) = {model.predict_proba([[0]])[0][1]:.2%}\")\n",
    "\n",
    "# Verificamos con los datos reales\n",
    "positivos = np.sum((pruebas == 1) & (enfermos == 1)) / np.sum(pruebas == 1)\n",
    "print(f\"\\nProporción real en los datos simulados:\")\n",
    "print(f\"P(Enfermo|Positivo) real = {positivos:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One place where multinomial naive Bayes is often used is in text classification, where the features are related to word counts or frequencies within the documents to be classified. We discussed the extraction of such features from text in Feature Engineering; here we will use the sparse word count features from the 20 Newsgroups corpus to show how we might classify these short documents into categories.\n",
    "\n",
    "Let's download the data and take a look at the target names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fetch_20newsgroups\n\u001b[1;32m----> 3\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_20newsgroups\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m data\u001b[38;5;241m.\u001b[39mtarget_names\n",
      "File \u001b[1;32mc:\\Users\\luis.bolanoss\\Documents\\Labs\\repositories\\data-science-handbook\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\luis.bolanoss\\Documents\\Labs\\repositories\\data-science-handbook\\.venv\\Lib\\site-packages\\sklearn\\datasets\\_twenty_newsgroups.py:320\u001b[0m, in \u001b[0;36mfetch_20newsgroups\u001b[1;34m(data_home, subset, categories, shuffle, random_state, remove, download_if_missing, return_X_y, n_retries, delay)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download_if_missing:\n\u001b[0;32m    319\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading 20news dataset. This may take a few minutes.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 320\u001b[0m     cache \u001b[38;5;241m=\u001b[39m \u001b[43m_download_20newsgroups\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtwenty_home\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m20Newsgroups dataset not found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\luis.bolanoss\\Documents\\Labs\\repositories\\data-science-handbook\\.venv\\Lib\\site-packages\\sklearn\\datasets\\_twenty_newsgroups.py:85\u001b[0m, in \u001b[0;36m_download_20newsgroups\u001b[1;34m(target_dir, cache_path, n_retries, delay)\u001b[0m\n\u001b[0;32m     83\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecompressing \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, archive_path)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tarfile\u001b[38;5;241m.\u001b[39mopen(archive_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr:gz\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[1;32m---> 85\u001b[0m     \u001b[43mtarfile_extractall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m suppress(\u001b[38;5;167;01mFileNotFoundError\u001b[39;00m):\n\u001b[0;32m     88\u001b[0m     os\u001b[38;5;241m.\u001b[39mremove(archive_path)\n",
      "File \u001b[1;32mc:\\Users\\luis.bolanoss\\Documents\\Labs\\repositories\\data-science-handbook\\.venv\\Lib\\site-packages\\sklearn\\utils\\fixes.py:375\u001b[0m, in \u001b[0;36mtarfile_extractall\u001b[1;34m(tarfile, path)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtarfile_extractall\u001b[39m(tarfile, path):\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 375\u001b[0m         \u001b[43mtarfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextractall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    377\u001b[0m         tarfile\u001b[38;5;241m.\u001b[39mextractall(path)\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.13.0\\Lib\\tarfile.py:2334\u001b[0m, in \u001b[0;36mTarFile.extractall\u001b[1;34m(self, path, members, numeric_owner, filter)\u001b[0m\n\u001b[0;32m   2329\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tarinfo\u001b[38;5;241m.\u001b[39misdir():\n\u001b[0;32m   2330\u001b[0m         \u001b[38;5;66;03m# For directories, delay setting attributes until later,\u001b[39;00m\n\u001b[0;32m   2331\u001b[0m         \u001b[38;5;66;03m# since permissions can interfere with extraction and\u001b[39;00m\n\u001b[0;32m   2332\u001b[0m         \u001b[38;5;66;03m# extracting contents can reset mtime.\u001b[39;00m\n\u001b[0;32m   2333\u001b[0m         directories\u001b[38;5;241m.\u001b[39mappend(tarinfo)\n\u001b[1;32m-> 2334\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtarinfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2335\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mnumeric_owner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_owner\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2337\u001b[0m \u001b[38;5;66;03m# Reverse sort directories.\u001b[39;00m\n\u001b[0;32m   2338\u001b[0m directories\u001b[38;5;241m.\u001b[39msort(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m a: a\u001b[38;5;241m.\u001b[39mname, reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.13.0\\Lib\\tarfile.py:2397\u001b[0m, in \u001b[0;36mTarFile._extract_one\u001b[1;34m(self, tarinfo, path, set_attrs, numeric_owner)\u001b[0m\n\u001b[0;32m   2394\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2396\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2397\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_member\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarinfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2398\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mset_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mset_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2399\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mnumeric_owner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_owner\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2400\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   2401\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_fatal_error(e)\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.13.0\\Lib\\tarfile.py:2480\u001b[0m, in \u001b[0;36mTarFile._extract_member\u001b[1;34m(self, tarinfo, targetpath, set_attrs, numeric_owner)\u001b[0m\n\u001b[0;32m   2477\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbg(\u001b[38;5;241m1\u001b[39m, tarinfo\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   2479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tarinfo\u001b[38;5;241m.\u001b[39misreg():\n\u001b[1;32m-> 2480\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakefile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargetpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2481\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m tarinfo\u001b[38;5;241m.\u001b[39misdir():\n\u001b[0;32m   2482\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmakedir(tarinfo, targetpath)\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.13.0\\Lib\\tarfile.py:2534\u001b[0m, in \u001b[0;36mTarFile.makefile\u001b[1;34m(self, tarinfo, targetpath)\u001b[0m\n\u001b[0;32m   2532\u001b[0m     target\u001b[38;5;241m.\u001b[39mtruncate()\n\u001b[0;32m   2533\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2534\u001b[0m     \u001b[43mcopyfileobj\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarinfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mReadError\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.13.0\\Lib\\tarfile.py:259\u001b[0m, in \u001b[0;36mcopyfileobj\u001b[1;34m(src, dst, length, exception, bufsize)\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buf) \u001b[38;5;241m<\u001b[39m remainder:\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munexpected end of data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 259\u001b[0m     \u001b[43mdst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "data = fetch_20newsgroups()\n",
    "data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fetch_20newsgroups' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m categories \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtalk.religion.misc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoc.religion.christian\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      2\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msci.space\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomp.graphics\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m train \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_20newsgroups\u001b[49m(subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, categories\u001b[38;5;241m=\u001b[39mcategories)\n\u001b[0;32m      4\u001b[0m test \u001b[38;5;241m=\u001b[39m fetch_20newsgroups(subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, categories\u001b[38;5;241m=\u001b[39mcategories)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fetch_20newsgroups' is not defined"
     ]
    }
   ],
   "source": [
    "categories = ['talk.religion.misc', 'soc.religion.christian',\n",
    "              'sci.space', 'comp.graphics']\n",
    "train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "test = fetch_20newsgroups(subset='test', categories=categories)\n",
    "\n",
    "print(train.data[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 1.0\n",
      "Matriz de Confusión:\n",
      " [[1 0]\n",
      " [0 2]]\n",
      "Reporte de Clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         3\n",
      "   macro avg       1.00      1.00      1.00         3\n",
      "weighted avg       1.00      1.00      1.00         3\n",
      "\n",
      "Coeficientes: [[0.97522929 0.34657993]]\n",
      "Intercepto: [-6.25826117]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Datos de ejemplo\n",
    "data = {\n",
    "    'Horas_Estudio': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
    "    'Horas_Sueño': [7, 6, 5, 6, 7, 8, 7, 6, 5, 4],\n",
    "    'Aprobado': [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]  # 0: No aprobado, 1: Aprobado\n",
    "}\n",
    "\n",
    "# Crear un DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Separar características (X) y etiquetas (y)\n",
    "X = df[['Horas_Estudio', 'Horas_Sueño']]\n",
    "y = df['Aprobado']\n",
    "\n",
    "# Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Crear y entrenar el modelo de regresión logística\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predecir en el conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "\n",
    "# La precisión es una métrica que mide el porcentaje de predicciones sobre los datos de prueba, correctas del modelo sobre el total de predicciones realizadas.\n",
    "print(\"Precisión:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# La matriz de confusión es una tabla que muestra el desempeño del modelo en términos de:\n",
    "# Verdaderos Negativos (TN): Casos negativos correctamente clasificados.\n",
    "# Falsos Positivos (FP): Casos negativos incorrectamente clasificados como positivos.\n",
    "# Falsos Negativos (FN): Casos positivos incorrectamente clasificados como negativos.\n",
    "# Verdaderos Positivos (TP): Casos positivos correctamente clasificados.\n",
    "# [[TN, FP],\n",
    "#  [FN, TP]]\n",
    "print(\"Matriz de Confusión:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# El reporte de clasificación proporciona métricas detalladas para evaluar el desempeño del modelo en cada clase. Las métricas principales son:\n",
    "# Precisión (Precision): Proporción de predicciones positivas correctas sobre el total de predicciones positivas.\n",
    "# Recall (Sensibilidad): Proporción de casos positivos correctamente identificados sobre el total de casos positivos reales.\n",
    "# F1-Score: Media armónica entre precisión y recall. Es útil cuando hay un desbalance entre clases.\n",
    "# Soporte (Support): Número de ocurrencias de cada clase en el conjunto de prueba.\n",
    "# \n",
    "# Precisión: Indica cuán confiable es el modelo al predecir una clase.\n",
    "# Recall: Indica cuán bien el modelo identifica todos los casos positivos.\n",
    "# F1-Score: Es una métrica balanceada entre precisión y recall.\n",
    "# Soporte: Nos dice cuántos casos hay de cada clase en el conjunto de prueba.\n",
    "print(\"Reporte de Clasificación:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Coeficientes del modelo\n",
    "# Los coeficientes son los valores que multiplican cada característica en la ecuación de la regresión logística. Representan la contribución de cada característica a la predicción.\n",
    "print(\"Coeficientes:\", model.coef_)\n",
    "\n",
    "# El intercepto es el término independiente en la ecuación de la regresión logística. Representa el valor de z (la combinación lineal de características) cuando todas las características son 0.\n",
    "print(\"Intercepto:\", model.intercept_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
